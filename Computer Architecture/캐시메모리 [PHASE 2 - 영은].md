## 등장 배경

cpu가 메모리에 접근하는 시간은 cpu 연산 속도보다 느리다.

cpu의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 **`캐시 메모리`** 탄생

→ cpu가 매번 메모리에 왔다 갔다 하는 건 시간이 오래 걸림. 메모리에서 cpu가 사용할 일부 데이터를 미리 캐시 메모리에 저장해 사용

## 캐시 메모리란?

cpu와 메모리 사이에 위치한, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장장치

자주 사용하는 데이터를 메인 메모리보다 더 빠른 캐시 메모리에 위치시켜 CPU의 데이터 접근 성능을 높이기 위해 사용

## 캐시 히트와 캐시 미스

### **`Cache Hit`**

cpu에서 필요로 하는 데이터가 **캐시 메모리**에 존재하는 경우 

![image](https://github.com/user-attachments/assets/c882c57d-6b2e-41a3-9064-03ec0f643ba6)


### **`Cache Miss`**

cpu에서 필요로 하는 데이터가 캐시 메모리에 존재하지 않아, **메모리**에서 가져오는 경우 

![image](https://github.com/user-attachments/assets/4e9ccdd7-497f-419b-ba92-0bbe2015d6d0)

## 캐시메모리에 저장할 데이터 선정 방법

> cpu가 자주 사용할 법한 내용을 예측하여 저장해야함
> 

```python
for (i = 0; i < 10; i += 1) {
  arr[i] = i;
}
```

### `시간적 지역성`

- 최근에 접근된 데이터
- 짧은 시간 여러번 접근이 이루어 지는 for문의 i

### `공간적 지역성`

- 최근에 접근된 데이터의 주변 데이터
- arr[0], arr[1] 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음

## 캐시메모리 종류

L1 캐시: cpu와 가장 가까운 캐시 메모리

L2 캐시

L3 캐시 

```docker
메모리 용량: L1 < L2 < L3
속도: L3 < L2 < L1
가격: L3 < L2 < L1
```

### **`멀티 코어 프로세스`**

![image](https://github.com/user-attachments/assets/f2f6fb97-5157-43e7-9f4c-ce0fa19507ba)

L1 캐시와 L2 캐시는 코어마다 고유한 캐시 메모리로 할당 → 캐시 일관성 문제 고려

L3 캐시는 여러 코어가 공유

> 업체마다 구체적인 정책은 다르다고 한다.
> 

### ❓질문

### 캐시 메모리에서 가장 신경써야 하는 문제는 무엇인가요 ?

캐시 메모리의 역할을 수행하기 위해서는 CPU가 어떤 데이터를 원할 것인가를 예측할 수 있어야 합니다.

캐시 히트를 극대화 시켜야 합니다.

### 캐시 히트를 극대화 시키기 위한 방법에는 무엇이 있을까요 ?

적중률을 극대화 시키기 위해 **데이터 지역성(Locality)**의 원리를 사용합니다.

Locality란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성을 의미합니다.
