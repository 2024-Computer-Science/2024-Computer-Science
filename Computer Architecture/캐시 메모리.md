## ⭐️ 캐시(Cache)

사용되었던 데이터는 다시 사용될 가능성이 높다는 개념을 이용하여, 데이터나 값을 미리 복사해 두는 임시 장소이다.

![image](https://github.com/2024-Computer-Science/2024-Computer-Science/assets/83461362/406fa5e5-653e-4460-8389-cf8e195ff3a6)

- 중앙처리장치(CPU)와 주기억장치(memory) 간의 속도 차이 개선이 목적이다.
    
    <aside>
    💡 CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시에 저장하고 다음에 사용할 때 캐시에서 가져와 속도를 향상시키도록 한다.
    
    </aside>
    
- 시스템의 효율성을 위해 사용한다.
    - 원래 데이터를 접근하는 시간이 오래걸리는 경우
    - 값을 다시 계산하는 비용을 절약하고 싶은 경우
- 속도가 빠른 장치와 느린 장치 사이에서 속도차에 따른 병목현상을 완화하기 위한 범용 메모리이다.

종류

- CPU 캐시
    
    대용량의 메인 메모리 접근을 빠르게하기 위해 CPU 칩 내부나 바로 옆에 탑재하는 작은 메모리로, 하드웨어를 통해 관리한다.
    
  ![image](https://github.com/2024-Computer-Science/2024-Computer-Science/assets/83461362/b0b87e87-7140-4b82-92d7-a6ec02c50ece)

    
    | 종류 | 설명 | CPU 성능에 직접적 영향 |
    | --- | --- | --- |
    | L1 캐시 | 일반적으로 CPU 칩안에 내장되어 데이터 사용 및 참조에 가장 먼저 사용되는 캐시 메모리 | O |
    | L2 캐시 | - L1 캐시 메모리와 용도와 역할이 비슷- 속도 : L1 캐시 > L2 캐시 > 일반메모리(RAM) | O |
    | L3 캐시 | - L1 캐시, L2 캐시와 동일한 원리로 작동- 대부분 CPU가 아닌 메인보드에 내장 | X |
    
    듀얼 코어 프로세서의 경우, 각 코어마다 독립된 L1 캐시를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 저장된다. 
    
    - 캐시 메모리는 가격이 비싸서 크기가 매우 작음
- 디스크 캐시(디스크 버퍼)
    
    하드 디스크에 내장된 작은 컴퓨터가 소유한 작은 메모리(디스크에 입출력되는 데이터를 저장하는 작은 메모리)
    
    **하드디스크와 주기억장치 사이에 존재**한다고 볼 수 있다. 
    
- 그 외
    
    소프트웨어적인 캐시나, 페이지 캐시( 운영체제의 메인 메모리를 하드 디스크에 복사해두는 캐시)
    

---

**캐시가 효율적으로 동작하기 위해서는 캐시가 저장할 데이터가 지역성을 가져야한다.**

메모리에서 가져오게 되면 시스템 버스를 기반으로 작동하기 때문에 **속도가 느리다.** 

- 지역성 : 데이터의 접근이 시간적, 혹은 공간적으로 가깝게 일어나는 것
    - **시간적 지역성**(Temporal locality): 특정 데이터가 **한 번 접근**되었을 경우, 가까운 미래에 **또 한 번** 데이터에 접근할 가능성이 높다.
    - **공간적 지역성**(Spatial locality): 액세스 된 기억장소와 **인접한** 기억장소가 액세스 될 가능성이 높다.
- 캐시에 데이터를 저장할 때는 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터 뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다.

**[ 캐시히트(Cache Hit) ]**

캐시 메모리에 찾는 데이터가 **존재**하였을 때

**[ 캐시미스(Cache Miss) ]**

캐시 메모리에 찾는 데이터가 **존재하지 않을 때**, **메모리** 저장소로부터 필요한 데이터를 찾아 캐시 메모리에 로드

1. cold miss
    
    해당 메모리 주소를 처음 부름
    
2. conflict miss
    
    캐시에 A와 B를 저장해야 하는데 ,A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스
    
3. capacity miss
    
    캐시의 메모리 공간이 부족해서 나는 미스이다.
    

하지만 캐시 크기를 키우면 캐시 접근속도가 느려지고 그만큼의 파워를 필요로 한다. 특히 비싸다.

**[ 캐시매핑(Cache maaping) ]**

캐시가 히트되기 위해 매핑하는 방법

- Direct Mapped Cache
    
    ![image](https://github.com/2024-Computer-Science/2024-Computer-Science/assets/83461362/45bc179e-ad4f-4bc5-a67a-83701751866b)


가장 기본적인 구조, DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응(다대일) → conflict miss가 일어날 수 있음. 같은 색깔의 데이터를 동시에 사용해야 할 때 발생

ex) 00000, 01000, 10000, 11000인 메모리 주소는 000 캐시 메모리 주소에 맵핑

이때 000이 인덱스 필드, 00, 01 등이 태그 필드

- Fully Associative Cach
    
    비어있는 캐시 메모리에 마음대로 주소를 저장
    
    조건이나 규칙이 없어서 찾기 매우 힘들다.
    
    CAM이라는 특수한 메모리 구조를 사용해야되는데 매우 비싸다.
    
- Set Associative Cache
    
    direct + fully 방식으로, 특정 행을 지정하고, 그 행 안의 어떤 열이든 비어있으면 저장한다. direct에 비해 검색은 느리지만 저장이 빠르고 ,fully에비해 저장이 느리지만 검색을 빠르다.

참고
[👶🏻 신입 개발자 전공 지식 & 기술 면접 백과사전 📖](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%EC%BA%90%EC%8B%9C%20%EB%A9%94%EB%AA%A8%EB%A6%AC(Cache%20Memory).md)
[신입 개발자 면접 대비 CS 스터디 👨🏻‍💻👩🏻‍💻 🔥](https://github.com/devSquad-study/2023-CS-Study/blob/main/OS/os_memory_hierarchy.md)
