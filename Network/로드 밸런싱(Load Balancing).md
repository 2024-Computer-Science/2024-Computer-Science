# ⭐️ 로드 밸런싱(Load Balancing)
### 둘 이상의 CPU or 저장장치와 같은 컴퓨터 자원들에게 작업을 나누는 것

서버에 접속하는 사람들이 많아져 동시 접속자가 많아진다. → API 요청이 많아진다. → 모든 트래픽을 감당하기엔 1대의 서버로 부족하다!

### 대응 방안

**Scale-up : 하드웨어 성능을 올림**

**Scale-out : 서버를 증설**

![image](https://github.com/2024-Computer-Science/2024-Computer-Science/assets/83461362/ba9592e6-8f85-4177-88af-4a9f3074087d)

현대에는 스케일 아웃 전략, 즉 수평 확장 방식을 더 많이 사용한다.

### 이유

1. 유연성과 확장성
    - 서버나 리소스를 필요에 따라 추가하거나 제거할 수 있어 유연하다.
    - 서버를 추가적으로 배치하여 쉽게 확장할 수 있다. → 변화하는 비즈니스 요구사항과 트래픽 패턴에 효과적 대응 가능
2. 비용 효율성
    - 추가적인 고성능 서버를 구매하는 거보다 저렴한 하드웨어나 클라우드 리소스 여러개로 시스템을 확장할 수 있기 때문에, 초기 투자 비용과 운영 비용을 낮출 수 있다.
3. 고가용성
    - 여러 서버를 운영함으로써 하나의 서버가 실패하더라도 시스템 중단 없이 작업을 계속 할 수 있다. → 자연스럽게 고가용성 제공→  연속성을 보장하고,  장애 복구 시간을 최소화
4. 부하 분산
    - 작업 부하를 분산 시킬 수 있음
5. 클라우드 컴퓨팅
    - 클라우드 컴퓨팅 기술이 발전하여, 스케일 아웃을 사용하기 더 유용해졌다. 손쉽게 리소스를 추가하거나 줄일 수 있음

따라서 스케일 아웃이 효과적인 서버 확장 방법인데, 이 때 여러 서버에 부하(Load)를 균등하게 분산시켜주는 것이 **로드 밸런싱**

---

## 로드 밸런싱

분산식 웹 서비스로 , **Load Balancer**를 클라이언트와 서버사이에 두고, 부하가 일어나지 않게 여러 서버에 분산시켜준다. 

### 💡 서버 선택 방식

- **라운드 로빈(Round Robin)**: CPU 스케줄링의 라운드 로빈 방식
    
    각 대상에게 요청을 차례대로 전달한다. 3개의 서버가 있을 때 첫번째 요청 → 서버 1, 두번째 요청→ 서버2, 세번째 요청→ 서버3, 네번째 요청 → 서버1 이런식으로
    
    🥹 **단점**
    
    서버의 수가 일정하고 모든 서버가 동일한 성능을 가진다면 적절하지만, 서버의 수나 성능이 변하면 특정 서버가 부하를 많이 받거나 느려지는 등 문제가 발생한다.
    
- **가중 라운드 로빈(Weighted Round Robin) :** 서버마다 가중치를 매기고, 가중치가 높은 서버 우선 선택
    
    주로 서버의 트래픽 처리 능력이 상이한 경우 사용되는 방식으로, 성능이 우수한 서버에는 높은 가중치, 성능이 좋지 않은 서버에는 낮은 가중치를 설정한다.
    
     🥹 **단점**
    
    서버의 부하나 성능을 제대로 파악하지 못할 경우, 가중치 설정이 일정하지 않은 경우 불균등한 부하분산이 발생할 수 있다.
    

- **Least Connections(최소 연결 수):** 연결(세션) 개수가 가장 적은 서버 선택
    
    현재 연결된 수가 가장 적은 서버에 우선적으로 요청을 전달한다. 트래픽으로 인해 세션이 길어지는 경우 권장하는 방식이다.
    
     🥹 **단점**
    
    연결 수가 가장 적은 서버에만 요청 전달 → 대상 서버의 부하나 성능 상태를 고려하지 않으므로 부하 분산이 불균등할 수 있다.
    
- **Least Response time(최소 응답 시간) :** 가장 빠른 응답을 보이는 서버 선택
    
    서버의 현재 연결 상태와 응답 시간을 모두 고려하여 가장 짧은 응답 시간을 보내는 서버로 트래픽을 할당한다. 각 서버들의 가용 리소스나 성능, 처리중인 데이터 양 등이 다를 경우 적합하다.
    
     🥹 **단점**
    
    응답 시간 측정이 부정확한 경우 불균등한 부하 분산이 일어날 수 있다. 응답시간이 자주 변동하는 경우에도 부하 분산이 불안정해질 수 있다.
    
- **IP 해싱** : 클라이언트의 IP 주소를 해싱하여 대상 서버를 선택
    
    클라이언트가 항상 같은 서버로 연결되도록 보장하여 일관된 세션을 유지할 수 있다. 접속자가 많을 수록 분산 및 효율이 뛰어나다. 
    
    🥹 **단점**
    
    동일한 서버에 계속 요청을 보내는 해시 충돌 현상이 발생할 수 있고, 특정 서버에 부하가 집중될 수 있다.
    

---

주로 L4 로드 밸런서와 L7 로드 밸런서가 많이 활용된다.

**L4 로드 밸런서** 

- 네트워크 계층(4계층) or 전송 계층(3계층)의 정보를 바탕으로 로드 분산
- IP주소, 포트번호 등에 따라 트래픽 분산 가능
- 패킷의 내용을 확인하지 않고 로드 분산하므로 속도가 빠르고 효율이 높다.
- 가격이 저렴하다.
- 사용자의 IP가 수시로 바뀌면 연속적인 서비스를 제공하기 어렵다.

**L7 로드 밸런서**

- 애플리케이션 계층(7계층)에서 로드 분산
- HTTP 헤더, 쿠키 등과 같은 사용자 요청 기준으로 특정 서버에 트래픽 분산 가능
- → 세션 관리 가능
- 패킷의 내용을 확인하고 그 내용에 따라 로드 분산하기 때문에, 특정 패턴을 가지는 바이러스나 비정상적 트래픽을 필터링 할 수 있음
- 캐싱 기능을 제공
- L4에 비해 비싸고, 패킷 내용을 복호화해야하므로 비용이 높다.
- 클라이언트가 로드밸런서와 인증서를 공유해야하므로, 공격자가 로드밸런서를 통해 클라이언트 데이터에 접근할 수 있는 보안상 위험이 존재한다.

___ 

### 장애 대비

로드밸런서를 이중화하여 대비할 수 있다.

서로 헬스 체크 후, active상태인 Main 로드밸런서가 동작하지 않으면 여분의 로드 밸런서로 변경하여 이를 통해 운영한다.

___

### AWS 로드밸런서

ELB(Elastic Load Balancer) : 둘 이상의 가용 영역에서 EC2 인스턴스, IP 주소 등 여러 대상에 걸쳐 수신되는 트래픽을 자동 분산. 

- L4와 L7에 대한 부하를 제어할 수 있다.
- 뛰어난 확장성과 유연성을 제공하여 사용자의 다양한 요구 사항과 환경에 맞출 수 있다.

종류

- NLB(Network Load balancer) : IP주소 및 네트워크 정보를 검사하여 트래픽 리다이렉션.
    - L4 기반 로드밸런서
    - TCP/IP 프로토콜의 헤더를 보고 전송
    - 여러 서버에 고정 IP 주소를 할당할 수 있어 DNS Name과 IP 주소 모두 사용 가능
    - 고성능을 요구하는 환경에서 부하분산에 적합
    - 실시간 스트리밍 서비스, 화상 회의 or 채팅 애플리케이션에서 유리
- ALB(Application Load balacner) :  HTTP 헤더 or SSL 세션 ID와 같은 요청 콘텐츠를 확인하여 트래픽 리다이렉트.
    - L7 밸런서,  HTTP/HTTPS 헤더 정보를 이용해 부하분산하므로 해당 트래픽에 적합
    - SSL 적용 가능!
    - IP주소가 변경되므로 DNS Name을 이용
